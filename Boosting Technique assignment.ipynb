{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa5ed6-cd88-4d0e-8aec-2bf59d1204f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Boosting in Machine Learning? Explain how it improves weak learners.\n",
    "\n",
    "'''\n",
    "->Boosting is an ensemble learning technique in machine learning that combines multiple weak learners to create a strong learner with improved predictive performance.\n",
    "\n",
    " What is a Weak Learner?\n",
    "A weak learner is a model that performs just slightly better than random guessing. For example, in binary classification, a model with an accuracy slightly over 50% would be considered weak.\n",
    "\n",
    "Common weak learners:\n",
    "Shallow decision trees (also called decision stumps, i.e., trees with only one split)\n",
    "\n",
    " How It Improves Weak Learners:\n",
    "Boosting improves weak learners by:\n",
    "Focusing attention on the hardest examples.\n",
    "Reducing bias (since it builds multiple models sequentially and learns from mistakes).\n",
    "Converting high-bias models into low-bias ones through correction over time.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8c1b6-3b7a-474f-a868-d0ce3978d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the difference between AdaBoost and Gradient Boosting in terms of how models are trained?\n",
    "\n",
    "'''\n",
    "->| Feature                     | **AdaBoost**                                                                        | **Gradient Boosting**                                                                   |\n",
    "| --------------------------- | ----------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------- |\n",
    "| **Error Handling**          | Adjusts **weights** of training samples based on classification errors.             | Fits models to the **residuals (errors)** of the previous model using gradient descent. |\n",
    "| **Training Focus**          | Next learner focuses on **misclassified samples** (via increased weights).          | Next learner focuses on **minimizing the loss function’s gradient**.                    |\n",
    "| **Loss Function**           | Mainly designed for **classification** with exponential loss (but can be extended). | Can optimize **any differentiable loss function** (e.g., MSE, log-loss).                |\n",
    "| **Model Update Strategy**   | Weighted majority vote or sum of weak learners.                                     | Adds new learners to **correct residuals** from previous learners.                      |\n",
    "| **Mathematical Foundation** | Based on **reweighting examples**.                                                  | Based on **gradient descent in function space**.                                        |\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57986509-83d6-4a63-9568-aa994775b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How does regularization help in XGBoost?\n",
    "\n",
    "'''\n",
    "-> What Is Regularization?\n",
    "Regularization is the technique of adding a penalty to the loss function to discourage overly complex models. In XGBoost, it controls how much freedom the model has in fitting the training data.\n",
    "\n",
    "| Aspect                      | Effect of Regularization in XGBoost                                                                         |\n",
    "| --------------------------- | ----------------------------------------------------------------------------------------------------------- |\n",
    "| **Prevents Overfitting**    | Penalizes overly complex trees (e.g., very deep or with many leaves), which helps prevent memorizing noise. |\n",
    "| **Simplifies the Model**    | Encourages smaller trees with fewer splits, making the model easier to interpret and more robust.           |\n",
    "| **Improves Generalization** | Helps the model perform well on **new/unseen data**, not just the training set.                             |\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f854b1-15ef-479a-89c2-70d2e5dc00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why is CatBoost considered efficient for handling categorical data?\n",
    "\n",
    "'''\n",
    "->Key Reasons Why CatBoost Excels at Handling Categorical Data:\n",
    "1. No Need for Manual Encoding (Like One-Hot or Label Encoding)\n",
    "Most models (e.g., XGBoost, LightGBM) require:\n",
    "One-hot encoding → can massively increase dimensionality\n",
    "\n",
    " CatBoost automatically detects and processes categorical features directly during training.\n",
    "You just specify which features are categorical — no encoding needed!\n",
    "\n",
    "2.  Uses Target-Based Statistics (Without Overfitting)\n",
    "CatBoost transforms categorical values into numbers by calculating target statistics (like average target value for each category), but does this using a technique called:\n",
    "→ Ordered Target Encoding (also known as Ordered Boosting)\n",
    "It processes data in a specific order to avoid target leakage.\n",
    "\n",
    "Much safer and more accurate than traditional target encoding.\n",
    "\n",
    "3. Efficient Handling of High-Cardinality Categories\n",
    "CatBoost handles features with many unique categories (e.g., zip codes, product IDs) efficiently using:\n",
    "\n",
    "Combination of categorical features\n",
    "Efficient encoding without expanding feature space\n",
    "\n",
    "4. Faster Training with Categorical Features\n",
    "Because it avoids the overhead of:\n",
    "\n",
    "One-hot encoding (which increases data size)\n",
    "\n",
    "...CatBoost often trains faster and uses less memory, especially when datasets have many categorical variables.\n",
    "\n",
    "5.  Out-of-the-Box Performance\n",
    "CatBoost is known for:\n",
    "Requiring minimal data preprocessing\n",
    "Delivering high accuracy on datasets with many categorical features\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6436f6-02df-4922-a18b-c7ec4135f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are some real-world applications where boosting techniques are preferred over bagging methods?\n",
    "\n",
    "'''\n",
    "-> When Boosting Techniques Are Preferred Over Bagging\n",
    "1. When Accuracy on Hard-to-Predict Data is Crucial\n",
    "Boosting focuses on correcting mistakes of previous models, so it often achieves higher accuracy on complex datasets.\n",
    "\n",
    "Real-world tasks where tiny improvements matter, like:\n",
    "Fraud detection (credit cards, insurance)\n",
    "Spam filtering\n",
    "\n",
    "2. When the Problem Has a High Bias (Underfitting)\n",
    "Boosting reduces bias by sequentially building models that fix previous errors.\n",
    "Preferred when simple base models (weak learners) are too naive.\n",
    "\n",
    "Example applications:\n",
    "Medical diagnosis where subtle patterns must be identified\n",
    "\n",
    "3. When Data is Imbalanced\n",
    "Boosting methods like AdaBoost or Gradient Boosting can better handle imbalanced classes by focusing on misclassified minority samples.\n",
    "Used in:\n",
    "Fraud detection\n",
    "Rare event prediction (e.g., machine failure, disease outbreaks)\n",
    "\n",
    "4. When Feature Engineering is Limited\n",
    "Boosting algorithms, especially modern ones like XGBoost, LightGBM, and CatBoost, handle feature interactions and non-linearities automatically.\n",
    "\n",
    "Useful for:\n",
    "Customer behavior prediction\n",
    "Sales forecasting\n",
    "\n",
    "5. Competitions and Benchmarking\n",
    "Boosting techniques dominate many machine learning competitions (e.g., Kaggle) due to their accuracy and flexibility.\n",
    "\n",
    "6. When Interpretability is Needed with Good Performance\n",
    "Boosted trees can be interpreted (e.g., feature importance, SHAP values).\n",
    "\n",
    "Used in:\n",
    "Healthcare analytics\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7af5bb0-c3f4-4006-94da-ce2ed58c2d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Shukla\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier Accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "# Write a Python program to:● Train an AdaBoost Classifier on the Breast Cancer dataset● Print the model accuracy\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the AdaBoost Classifier\n",
    "model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"AdaBoost Classifier Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48cea049-f7d1-47ec-9857-7c43f7a12021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor R² Score: 0.7756\n"
     ]
    }
   ],
   "source": [
    "#Write a Python program to:● Train a Gradient Boosting Regressor on the California Housing dataset● Evaluate performance using R-squared score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate using R-squared score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the R-squared score\n",
    "print(f\"Gradient Boosting Regressor R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a63e02f-edd8-49a3-8ebc-d783cb75b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to:● Train an XGBoost Classifier on the Breast Cancer dataset● Tune the learning rate using GridSearchCV● Print the best parameters and accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b72169a4-2417-41b8-9129-0f6ea6e2387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading xgboost-3.0.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Downloading xgboost-3.0.4-py3-none-win_amd64.whl (56.8 MB)\n",
      "   ---------------------------------------- 0.0/56.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/56.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/56.8 MB 2.6 MB/s eta 0:00:22\n",
      "    --------------------------------------- 1.0/56.8 MB 2.5 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.0/56.8 MB 2.5 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.0/56.8 MB 2.5 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.0/56.8 MB 2.5 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.0/56.8 MB 2.5 MB/s eta 0:00:23\n",
      "    --------------------------------------- 1.3/56.8 MB 721.7 kB/s eta 0:01:17\n",
      "   - -------------------------------------- 1.8/56.8 MB 959.1 kB/s eta 0:00:58\n",
      "   - -------------------------------------- 2.4/56.8 MB 1.1 MB/s eta 0:00:50\n",
      "   -- ------------------------------------- 2.9/56.8 MB 1.3 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 3.1/56.8 MB 1.4 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 3.7/56.8 MB 1.4 MB/s eta 0:00:39\n",
      "   -- ------------------------------------- 4.2/56.8 MB 1.4 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 4.5/56.8 MB 1.5 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 5.2/56.8 MB 1.6 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 5.2/56.8 MB 1.6 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 5.2/56.8 MB 1.6 MB/s eta 0:00:33\n",
      "   --- ------------------------------------ 5.2/56.8 MB 1.6 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 5.8/56.8 MB 1.4 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 6.3/56.8 MB 1.4 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 6.8/56.8 MB 1.5 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 7.3/56.8 MB 1.6 MB/s eta 0:00:32\n",
      "   ----- ---------------------------------- 7.9/56.8 MB 1.6 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 8.4/56.8 MB 1.6 MB/s eta 0:00:30\n",
      "   ------ --------------------------------- 8.9/56.8 MB 1.7 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 9.7/56.8 MB 1.7 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.5/56.8 MB 1.8 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 10.7/56.8 MB 1.5 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 11.5/56.8 MB 1.6 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 12.3/56.8 MB 1.6 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 12.6/56.8 MB 1.7 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 12.6/56.8 MB 1.7 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 12.6/56.8 MB 1.7 MB/s eta 0:00:27\n",
      "   --------- ------------------------------ 12.8/56.8 MB 1.5 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 13.6/56.8 MB 1.6 MB/s eta 0:00:27\n",
      "   ---------- ----------------------------- 14.4/56.8 MB 1.7 MB/s eta 0:00:26\n",
      "   ---------- ----------------------------- 15.2/56.8 MB 1.7 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 15.7/56.8 MB 1.7 MB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 16.8/56.8 MB 1.6 MB/s eta 0:00:25\n",
      "   ----------- ---------------------------- 17.0/56.8 MB 1.6 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 17.6/56.8 MB 1.6 MB/s eta 0:00:25\n",
      "   ------------ --------------------------- 17.8/56.8 MB 1.6 MB/s eta 0:00:24\n",
      "   ------------ --------------------------- 17.8/56.8 MB 1.6 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 18.6/56.8 MB 1.6 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 19.4/56.8 MB 1.7 MB/s eta 0:00:23\n",
      "   -------------- ------------------------- 20.2/56.8 MB 1.7 MB/s eta 0:00:22\n",
      "   -------------- ------------------------- 21.0/56.8 MB 1.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------- 21.2/56.8 MB 1.7 MB/s eta 0:00:21\n",
      "   --------------- ------------------------ 21.8/56.8 MB 1.8 MB/s eta 0:00:20\n",
      "   --------------- ------------------------ 22.5/56.8 MB 1.8 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 23.1/56.8 MB 1.8 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 23.9/56.8 MB 1.7 MB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 1.7 MB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 24.1/56.8 MB 1.7 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 24.9/56.8 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 25.2/56.8 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 25.2/56.8 MB 1.6 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 25.2/56.8 MB 1.6 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 26.0/56.8 MB 1.6 MB/s eta 0:00:20\n",
      "   ------------------ --------------------- 26.5/56.8 MB 1.6 MB/s eta 0:00:19\n",
      "   ------------------- -------------------- 27.3/56.8 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 28.0/56.8 MB 1.7 MB/s eta 0:00:18\n",
      "   ------------------- -------------------- 28.3/56.8 MB 1.7 MB/s eta 0:00:17\n",
      "   -------------------- ------------------- 28.8/56.8 MB 1.7 MB/s eta 0:00:17\n",
      "   -------------------- ------------------- 29.4/56.8 MB 1.7 MB/s eta 0:00:17\n",
      "   --------------------- ------------------ 30.1/56.8 MB 1.7 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 30.7/56.8 MB 1.7 MB/s eta 0:00:16\n",
      "   --------------------- ------------------ 31.2/56.8 MB 1.7 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 32.0/56.8 MB 1.8 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 32.5/56.8 MB 1.8 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 33.0/56.8 MB 1.7 MB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 33.8/56.8 MB 1.7 MB/s eta 0:00:14\n",
      "   ------------------------ --------------- 34.6/56.8 MB 1.7 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 35.1/56.8 MB 1.7 MB/s eta 0:00:13\n",
      "   ------------------------- -------------- 35.9/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 36.7/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 36.7/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 36.7/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 37.2/56.8 MB 1.8 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 38.5/56.8 MB 1.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 39.1/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 39.8/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 40.1/56.8 MB 1.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 40.6/56.8 MB 1.8 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 41.7/56.8 MB 1.9 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 42.2/56.8 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 43.0/56.8 MB 1.9 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 43.8/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 44.0/56.8 MB 1.9 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 44.3/56.8 MB 1.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 45.4/56.8 MB 1.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 46.1/56.8 MB 1.8 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 46.7/56.8 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.2/56.8 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.2/56.8 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.2/56.8 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.2/56.8 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 47.7/56.8 MB 1.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 48.2/56.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 48.5/56.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 49.0/56.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 49.0/56.8 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 49.8/56.8 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 50.3/56.8 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 50.6/56.8 MB 1.8 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 51.1/56.8 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 51.6/56.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 52.4/56.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.0/56.8 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 53.7/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 54.5/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 55.1/56.8 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  55.6/56.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  55.8/56.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  56.6/56.8 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 56.8/56.8 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.4\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c00d06bf-43d8-49e2-a993-65aadbe9ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.2}\n",
      "Test Set Accuracy: 95.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya Shukla\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:55:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Define the parameter grid for learning_rate\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Test Set Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdd626-35ff-4a13-913d-63aaa4590981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a Python program to:● Train a CatBoost Classifier● Plot the confusion matrix using seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0225fce5-3826-4e60-91cc-c94bd7f8f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboostNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: seaborn in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\soumya shukla\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.3)\n",
      "Downloading catboost-1.2.8-cp312-cp312-win_amd64.whl (102.4 MB)\n",
      "   ---------------------------------------- 0.0/102.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/102.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/102.4 MB 1.9 MB/s eta 0:00:55\n",
      "   ---------------------------------------- 1.0/102.4 MB 2.2 MB/s eta 0:00:47\n",
      "    --------------------------------------- 1.6/102.4 MB 2.2 MB/s eta 0:00:46\n",
      "    --------------------------------------- 2.4/102.4 MB 2.5 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 2.9/102.4 MB 2.7 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 3.7/102.4 MB 2.8 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 4.5/102.4 MB 3.0 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.2/102.4 MB 3.0 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.0/102.4 MB 3.1 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 6.8/102.4 MB 3.2 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 7.6/102.4 MB 3.2 MB/s eta 0:00:30\n",
      "   --- ------------------------------------ 8.4/102.4 MB 3.3 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 8.9/102.4 MB 3.3 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 9.7/102.4 MB 3.3 MB/s eta 0:00:28\n",
      "   --- ------------------------------------ 10.2/102.4 MB 3.3 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 11.3/102.4 MB 3.4 MB/s eta 0:00:28\n",
      "   ---- ----------------------------------- 12.1/102.4 MB 3.4 MB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 13.1/102.4 MB 3.4 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 13.9/102.4 MB 3.5 MB/s eta 0:00:26\n",
      "   ----- ---------------------------------- 14.7/102.4 MB 3.5 MB/s eta 0:00:26\n",
      "   ------ --------------------------------- 15.5/102.4 MB 3.5 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 16.3/102.4 MB 3.5 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 17.0/102.4 MB 3.6 MB/s eta 0:00:25\n",
      "   ------ --------------------------------- 17.8/102.4 MB 3.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 18.6/102.4 MB 3.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 19.4/102.4 MB 3.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 19.9/102.4 MB 3.6 MB/s eta 0:00:24\n",
      "   ------- -------------------------------- 20.4/102.4 MB 3.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 21.2/102.4 MB 3.5 MB/s eta 0:00:24\n",
      "   -------- ------------------------------- 22.0/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   -------- ------------------------------- 22.8/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 23.6/102.4 MB 3.5 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.4/102.4 MB 3.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 25.2/102.4 MB 3.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.0/102.4 MB 3.6 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 27.0/102.4 MB 3.6 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 27.8/102.4 MB 3.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 28.6/102.4 MB 3.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.4/102.4 MB 3.6 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 30.1/102.4 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.9/102.4 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 31.7/102.4 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 32.8/102.4 MB 3.6 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 33.6/102.4 MB 3.7 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 34.1/102.4 MB 3.6 MB/s eta 0:00:19\n",
      "   ------------- -------------------------- 35.1/102.4 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 35.9/102.4 MB 3.7 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 37.0/102.4 MB 3.7 MB/s eta 0:00:18\n",
      "   -------------- ------------------------- 37.5/102.4 MB 3.6 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 38.5/102.4 MB 3.7 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 39.3/102.4 MB 3.7 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 40.1/102.4 MB 3.7 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 40.9/102.4 MB 3.7 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 41.9/102.4 MB 3.7 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 42.7/102.4 MB 3.7 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 43.0/102.4 MB 3.7 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 44.3/102.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 44.6/102.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 45.4/102.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 46.4/102.4 MB 3.7 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 46.9/102.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 48.0/102.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 48.8/102.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 49.8/102.4 MB 3.7 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 50.6/102.4 MB 3.7 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 50.9/102.4 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 51.9/102.4 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 52.7/102.4 MB 3.7 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 53.5/102.4 MB 3.7 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 54.5/102.4 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 55.1/102.4 MB 3.7 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 56.1/102.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 56.9/102.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 57.4/102.4 MB 3.7 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 58.5/102.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 59.2/102.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 60.3/102.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 60.8/102.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 61.3/102.4 MB 3.7 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 61.9/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 62.7/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 63.4/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 64.0/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 64.5/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 65.3/102.4 MB 3.7 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 66.1/102.4 MB 3.7 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 66.8/102.4 MB 3.7 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 67.6/102.4 MB 3.7 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 68.4/102.4 MB 3.7 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 69.2/102.4 MB 3.7 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 69.7/102.4 MB 3.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 70.5/102.4 MB 3.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 71.0/102.4 MB 3.7 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 71.3/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 71.8/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 72.6/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 73.4/102.4 MB 3.6 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 74.4/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 75.2/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 76.0/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 76.8/102.4 MB 3.6 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 77.9/102.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 78.4/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 79.2/102.4 MB 3.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 80.0/102.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 80.7/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 81.3/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 82.1/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 82.6/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 83.1/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 84.1/102.4 MB 3.6 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 84.9/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 85.7/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 86.5/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 87.6/102.4 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 88.1/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 88.9/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 89.7/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 90.2/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 91.0/102.4 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 91.8/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 92.8/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 93.6/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 94.4/102.4 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 95.2/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 95.7/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 96.5/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 97.0/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 97.8/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 98.3/102.4 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 99.1/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 99.6/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.1/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.9/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  101.4/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.0/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 102.4/102.4 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21\n"
     ]
    }
   ],
   "source": [
    "pip install catboost seaborn scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551a1c48-0cc3-46d9-94cb-2e1979ab9dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load sample dataset (Breast Cancer classification)\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train CatBoostClassifier (silent training)\n",
    "model = CatBoostClassifier(verbose=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix using seaborn\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948cf4a8-f841-4346-8d4e-33ede92cec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You're working for a FinTech company trying to predict loan default usingcustomer demographics and transaction behavior.The dataset is imbalanced, contains missing values, and has both numeric and categorical features.Describe your step-by-step data science pipeline using boosting techniques:● Data preprocessing & handling missing/categorical values● Choice between AdaBoost, XGBoost, or CatBoost● Hyperparameter tuning strategy● Evaluation metrics you'd choose and why● How the business would benefit from your model\n",
    "\n",
    "'''\n",
    "->1. Data Preprocessing\n",
    " Handle Missing Values\n",
    "Numerical features:\n",
    "Use mean/median imputation (prefer median if outliers are present).\n",
    "Alternatively, use model-based imputation (e.g., KNN or iterative imputer).\n",
    "\n",
    "Categorical features:\n",
    "Use a placeholder like \"Unknown\" or mode imputation.\n",
    "\n",
    "Encode Categorical Features\n",
    "If using CatBoost: No encoding needed – it handles raw categories.\n",
    "If using XGBoost or AdaBoost:\n",
    "Use one-hot encoding for low-cardinality features.\n",
    "\n",
    " Feature Engineering\n",
    "Create domain-specific features like:\n",
    "Debt-to-income ratio\n",
    "Average monthly spend\n",
    "\n",
    "2. Handle Imbalanced Dataset\n",
    "Loan default is often a rare event, so you'll want to:\n",
    "Use SMOTE or ADASYN for oversampling (only on training data)\n",
    "E.g., scale_pos_weight in XGBoost\n",
    "\n",
    "3. Business Impact\n",
    "Why the model is valuable:\n",
    " Early Risk Detection: Identify high-risk borrowers before issuing loans\n",
    "Loss Prevention: Reduce default-related financial losses\n",
    " Portfolio Optimization: Adjust credit policies for high-risk segments\n",
    "\n",
    " Final Thoughts\n",
    "This pipeline:\n",
    "Leverages CatBoost for minimal preprocessing\n",
    "Incorporates robust tuning and validation\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
